/*
 *Very Large Integer Library, License - Version 1.0 - May 3rd, 2012
 *
 *Timothee Ewart - University of Geneva,
 *Andreas Hehn - Swiss Federal Institute of technology Zurich.
 *Maxim Milakov - NVIDIA
 *
 *Permission is hereby granted, free of charge, to any person or organization
 *obtaining a copy of the software and accompanying documentation covered by
 *this license (the "Software") to use, reproduce, display, distribute,
 *execute, and transmit the Software, and to prepare derivative works of the
 *Software, and to permit third-parties to whom the Software is furnished to
 *do so, all subject to the following:
 *
 *The copyright notices in the Software and this entire statement, including
 *the above license grant, this restriction and the following disclaimer,
 *must be included in all copies of the Software, in whole or in part, and
 *all derivative works of the Software, unless such copies or derivative
 *works are solely in the form of machine-executable object code generated by
 *a source language processor.
 *
 *THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 *IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 *FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
 *SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
 *FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
 *ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 *DEALINGS IN THE SOFTWARE.
 */


namespace vli {
    namespace detail {

    #define VLI__ExtendStride result_stride<0, 4, Order>::value // 2*order+1
    #define VLI__SIZE num_words<NumBits>::value 
    // all this could be really simplified as the max_order version
    template <std::size_t NumBits, class MaxOrder, int NumVars>
    struct accelerator;

    // 4 variables
    template <std::size_t NumBits, int Order>
    struct accelerator<NumBits, max_order_combined<Order>, 4>{
    inline static __device__ void polynomial_multiplication_max_order( const unsigned int element_count, unsigned int*  out, unsigned int*  workblock_count_by_warp, single_coefficient_task* execution_plan) {

        const unsigned int local_thread_id = threadIdx.x;
        const unsigned int element_id = blockIdx.x;
        
        unsigned int c1[VLI__SIZE],c2[VLI__SIZE];
        unsigned int res[2*VLI__SIZE];

        unsigned int res1[2*VLI__SIZE];
        
        unsigned int iteration_count = workblock_count_by_warp[local_thread_id / 32];
        
        const unsigned int input_elem_offset = element_id *  vli::detail::max_order_combined_helpers::size<4+1, Order>::value * VLI__SIZE;
        
        for(unsigned int iteration_id = 0; iteration_id < iteration_count; ++iteration_id) {
            single_coefficient_task task = execution_plan[local_thread_id + (iteration_id * mul_block_size<max_order_combined<2*Order>,4>::value)];
            const unsigned int step_count = task.step_count;
        
            if (step_count > 0) {
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                    res[i] = 0;
                
                const int output_degree_x = task.output_degree_x;
                const int output_degree_y = task.output_degree_y;
                const int output_degree_z = task.output_degree_z;
                const int output_degree_w = task.output_degree_w;

                for(int current_degree_x=max(0, output_degree_x-Order); current_degree_x <= min(output_degree_x,Order) ;++current_degree_x)
                    for(int current_degree_y=max(0, output_degree_x+output_degree_y-Order-current_degree_x); current_degree_y <= min(output_degree_y,Order-current_degree_x) ; ++current_degree_y)
                        for(int current_degree_z=max(0, output_degree_x+output_degree_y+output_degree_z-Order-current_degree_x-current_degree_y); current_degree_z <= min(output_degree_z,Order-current_degree_x - current_degree_y) ; ++current_degree_z)
                            for(int current_degree_w=max(0, output_degree_x+output_degree_y+output_degree_z+output_degree_w-Order-current_degree_x-current_degree_y-current_degree_z); current_degree_w <= min(output_degree_w,Order-current_degree_x - current_degree_y - current_degree_z) ; ++current_degree_w){
                
                             unsigned int in_polynomial_offset1 = ( //0____0'
                                                                   (current_degree_x*(2*(Order+1)+3-current_degree_x)*(2*(Order+1)*(Order+1)+6*(Order+1)+2 +current_degree_x*current_degree_x -2*(Order+1)*current_degree_x
                                                                   - 3*current_degree_x))/24
                                                                   +(current_degree_y*(current_degree_y*current_degree_y - 3*current_degree_y*((Order+1)+1-current_degree_x) + 3*((Order+1)-current_degree_x)*((Order+1)+2-current_degree_x)+2))/6
                                                                   +((Order+1)-current_degree_x-current_degree_y)*current_degree_z - (current_degree_z*current_degree_z-current_degree_z)/2 + current_degree_w
                                                                  ) * VLI__SIZE + input_elem_offset;
                             
                             unsigned int in_polynomial_offset2 = ( //*.* 
                                                                   ((output_degree_x-current_degree_x)*(2*(Order+1)+3-(output_degree_x-current_degree_x))*(2*(Order+1)*(Order+1)+6*(Order+1)+2
                                                                     + (output_degree_x-current_degree_x)*(output_degree_x-current_degree_x) -2*(Order+1)*(output_degree_x-current_degree_x)
                                                                     - 3*(output_degree_x-current_degree_x)))/24
                                                                   +((output_degree_y-current_degree_y)*((output_degree_y-current_degree_y)*(output_degree_y-current_degree_y) - 3*(output_degree_y-current_degree_y)*((Order+1)+1-(output_degree_x-current_degree_x))
                                                                     + 3*((Order+1)-(output_degree_x-current_degree_x))*((Order+1)+2-(output_degree_x-current_degree_x))+2))/6
                                                                   +((Order+1)-(output_degree_x-current_degree_x)-(output_degree_y-current_degree_y))*(output_degree_z-current_degree_z) 
                                                                     - ((output_degree_z-current_degree_z)*(output_degree_z-current_degree_z)-(output_degree_z-current_degree_z))/2 + (output_degree_w-current_degree_w)
                                                                  ) * VLI__SIZE + input_elem_offset;
                             
                             #pragma unroll
                             for(unsigned int i = 0; i < VLI__SIZE; ++i){
                                 c1[i] = tex1Dfetch(tex_reference_1,in_polynomial_offset1+i);        
                            }
                             #pragma unroll
                             for(unsigned int i = 0; i < VLI__SIZE; ++i){
                                 c2[i] = tex1Dfetch(tex_reference_2,in_polynomial_offset2+i);                 
                             } 
                             
                             #pragma unroll
                             for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                                 res1[i] = 0;
                             
                             multiplies<NumBits>(res, res1, c1, c2); // the multiplication using boost pp
                    } //end big loop

                unsigned int coefficient_id = (output_degree_x*(2*VLI__ExtendStride+3-output_degree_x)*(2*VLI__ExtendStride*VLI__ExtendStride+6*VLI__ExtendStride+2 +output_degree_x*output_degree_x -2*VLI__ExtendStride*output_degree_x
                                              - 3*output_degree_x))/24
                                              +(output_degree_y*(output_degree_y*output_degree_y - 3*output_degree_y*(VLI__ExtendStride+1-output_degree_x) + 3*(VLI__ExtendStride-output_degree_x)*(VLI__ExtendStride+2-output_degree_x)+2))/6
                                              +(VLI__ExtendStride-output_degree_x-output_degree_y)*output_degree_z - (output_degree_z*output_degree_z-output_degree_z)/2 + output_degree_w;
                
                unsigned int * out2 = out + (coefficient_id * element_count *2* VLI__SIZE) + element_id; // coefficient->int_degree->element_id
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i) {
                        // This is a strongly compute-bound kernel,
                        // so it is fine to waste memory bandwidth by using non-coalesced writes in order to have less instructions,
                        //     less synchronization points, less shared memory used (and thus greater occupancy) and greater scalability.
                        *out2 = res[i];
                        out2 += element_count;
                }
            } // end step count
        } // end for it

        }; // end function
    }; //end struct

    // 3 variables
    template <std::size_t NumBits, int Order>
    struct accelerator<NumBits, max_order_combined<Order>, 3>{
    inline static __device__ void polynomial_multiplication_max_order( const unsigned int element_count, unsigned int*  out, unsigned int*  workblock_count_by_warp, single_coefficient_task* execution_plan) {

        const unsigned int local_thread_id = threadIdx.x;
        const unsigned int element_id = blockIdx.x;
        
        unsigned int c1[VLI__SIZE],c2[VLI__SIZE];
        unsigned int res[2*VLI__SIZE];
        unsigned int res1[2*VLI__SIZE];
        
        unsigned int iteration_count = workblock_count_by_warp[local_thread_id / 32];
        
        const unsigned int input_elem_offset = element_id * vli::detail::max_order_combined_helpers::size<3+1, Order>::value  * VLI__SIZE;
        
        for(unsigned int iteration_id = 0; iteration_id < iteration_count; ++iteration_id) {
            single_coefficient_task task = execution_plan[local_thread_id + (iteration_id * mul_block_size<max_order_combined<2*Order>, 3>::value)];
            const unsigned int step_count = task.step_count;
        
            if (step_count > 0) {
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                    res[i] = 0;
                
                const int output_degree_x = task.output_degree_x;
                const int output_degree_y = task.output_degree_y;
                const int output_degree_z = task.output_degree_z;

                for(int current_degree_x=max(0, output_degree_x-Order); current_degree_x <= min(output_degree_x,Order) ;++current_degree_x)
                    for(int current_degree_y=max(0, output_degree_x+output_degree_y-Order-current_degree_x); current_degree_y <= min(output_degree_y,Order-current_degree_x) ; ++current_degree_y)
                        for(int current_degree_z=max(0, output_degree_x+output_degree_y+output_degree_z-Order-current_degree_x-current_degree_y); current_degree_z <= min(output_degree_z,Order-current_degree_x - current_degree_y) ; ++current_degree_z){
                
                        unsigned int in_polynomial_offset1 = (
                                                              (current_degree_x*(current_degree_x*current_degree_x - 3*current_degree_x*((Order+1)+1)
                                                              + 3*(Order+1)*((Order+1)+2) +2))/6
                                                              + ((Order+1) - current_degree_x)*current_degree_y - (current_degree_y*current_degree_y-current_degree_y)/2 + current_degree_z
                                                             ) * VLI__SIZE + input_elem_offset;
      
                        
                        unsigned int in_polynomial_offset2 = ( 
                                                              ((output_degree_x-current_degree_x)*((output_degree_x-current_degree_x)*(output_degree_x-current_degree_x) - 3*(output_degree_x-current_degree_x)*((Order+1)+1)
                                                              + 3*(Order+1)*((Order+1)+2) +2))/6
                                                              + ((Order+1) - (output_degree_x-current_degree_x))*(output_degree_y-current_degree_y) - ((output_degree_y-current_degree_y)*(output_degree_y-current_degree_y)-(output_degree_y-current_degree_y))/2
                                                              + (output_degree_z-current_degree_z)
                                                             ) * VLI__SIZE + input_elem_offset;
                        #pragma unroll
                        for(unsigned int i = 0; i < VLI__SIZE; ++i){
                            c1[i] = tex1Dfetch(tex_reference_1,in_polynomial_offset1+i);        
                       }
                        #pragma unroll
                        for(unsigned int i = 0; i < VLI__SIZE; ++i){
                            c2[i] = tex1Dfetch(tex_reference_2,in_polynomial_offset2+i);                 
                        } 
                          
                        #pragma unroll
                        for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                            res1[i] = 0;
                     
                        multiplies<NumBits>(res, res1, c1, c2); // the multiplication using boost pp
                }
                
                unsigned int coefficient_id =  (output_degree_x*(output_degree_x*output_degree_x - 3*output_degree_x*(VLI__ExtendStride+1)
                                               + 3*VLI__ExtendStride*(VLI__ExtendStride+2) +2))/6
                                               + (VLI__ExtendStride - output_degree_x)*output_degree_y - (output_degree_y*output_degree_y-output_degree_y)/2 + output_degree_z;
                
                unsigned int * out2 = out + (coefficient_id * element_count *2* VLI__SIZE) + element_id; // coefficient->int_degree->element_id
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i) {
                        // This is a strongly compute-bound kernel,
                        // so it is fine to waste memory bandwidth by using non-coalesced writes in order to have less instructions,
                        //     less synchronization points, less shared memory used (and thus greater occupancy) and greater scalability.
                        *out2 = res[i];
                        out2 += element_count;
                }
            } // end step count
        } // end for it

        }; //end function
    }; //end struct

    // 2 variables
    template <std::size_t NumBits, int Order>
    struct accelerator<NumBits, max_order_combined<Order>, 2>{
    inline static __device__ void polynomial_multiplication_max_order( const unsigned int element_count, unsigned int*  out, unsigned int*  workblock_count_by_warp, single_coefficient_task* execution_plan) {

        const unsigned int local_thread_id = threadIdx.x;
        const unsigned int element_id = blockIdx.x;
        
        unsigned int c1[VLI__SIZE],c2[VLI__SIZE];
        unsigned int res[2*VLI__SIZE];
        unsigned int res1[2*VLI__SIZE];
        
        unsigned int iteration_count = workblock_count_by_warp[local_thread_id / 32];
        
        const unsigned int input_elem_offset = element_id * vli::detail::max_order_combined_helpers::size<2+1, Order>::value  * VLI__SIZE;
        
        for(unsigned int iteration_id = 0; iteration_id < iteration_count; ++iteration_id) {
            single_coefficient_task task = execution_plan[local_thread_id + (iteration_id * mul_block_size<max_order_combined<2*Order>, 2>::value)];
            const unsigned int step_count = task.step_count;
        
            if (step_count > 0) {
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                    res[i] = 0;
                
                const int output_degree_x = task.output_degree_x;
                const int output_degree_y = task.output_degree_y;
                //note min and max are in numeric 
                for(int current_degree_x=max(0, output_degree_x-Order); current_degree_x <= min(output_degree_x,Order) ;++current_degree_x)
                    for(int current_degree_y=max(0, output_degree_x+output_degree_y-Order-current_degree_x); current_degree_y <= min(output_degree_y,Order-current_degree_x) ; ++current_degree_y){
                        unsigned int in_polynomial_offset1 = (  
                                                               (Order+1)*current_degree_x - (current_degree_x*current_degree_x-current_degree_x)/2 + current_degree_y
                                                             ) * VLI__SIZE + input_elem_offset;
                        
                        unsigned int in_polynomial_offset2 = ( 
                                                               (Order+1)*(output_degree_x-current_degree_x) - ((output_degree_x-current_degree_x)*(output_degree_x-current_degree_x)-(output_degree_x-current_degree_x))/2 + (output_degree_y-current_degree_y)
                                                             ) * VLI__SIZE + input_elem_offset;
                        #pragma unroll
                        for(unsigned int i = 0; i < VLI__SIZE; ++i){
                            c1[i] = tex1Dfetch(tex_reference_1,in_polynomial_offset1+i);        
                        }
                        #pragma unroll
                        for(unsigned int i = 0; i < VLI__SIZE; ++i){
                            c2[i] = tex1Dfetch(tex_reference_2,in_polynomial_offset2+i);                 
                        } 
                    
                        #pragma unroll
                        for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                            res1[i] = 0;
                     
                        multiplies<NumBits>(res, res1, c1, c2); // the multiplication using boost pp
                    }                   

                unsigned int coefficient_id = VLI__ExtendStride*output_degree_x - (output_degree_x*output_degree_x-output_degree_x)/2 + output_degree_y;
                unsigned int * out2 = out + (coefficient_id * element_count *2* VLI__SIZE) + element_id; // coefficient->int_degree->element_id
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i) {
                        // This is a strongly compute-bound kernel,
                        // so it is fine to waste memory bandwidth by using non-coalesced writes in order to have less instructions,
                        //     less synchronization points, less shared memory used (and thus greater occupancy) and greater scalability.
                        *out2 = res[i];
                        out2 += element_count;
                }
            } // end step count
        } // end for it

        }; //end function
    };// end struct

    // 1 variables
    template <std::size_t NumBits, int Order>
    struct accelerator<NumBits, max_order_combined<Order>, 1>{
    inline static __device__ void polynomial_multiplication_max_order( const unsigned int element_count, unsigned int*  out, unsigned int*  workblock_count_by_warp, single_coefficient_task* execution_plan) {

        const unsigned int local_thread_id = threadIdx.x;
        const unsigned int element_id = blockIdx.x;
        
        unsigned int c1[VLI__SIZE],c2[VLI__SIZE];
        unsigned int res[2*VLI__SIZE];
        unsigned int res1[2*VLI__SIZE];
        
        unsigned int iteration_count = workblock_count_by_warp[local_thread_id / 32];
        
        const unsigned int input_elem_offset = element_id * stride<0,1,Order>::value * VLI__SIZE;
        
        for(unsigned int iteration_id = 0; iteration_id < iteration_count; ++iteration_id) {
            single_coefficient_task task = execution_plan[local_thread_id + (iteration_id * mul_block_size<max_order_combined<2*Order>, 1>::value)];
            const unsigned int step_count = task.step_count;
        
            if (step_count > 0) {
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                    res[i] = 0;
                
                const unsigned int output_degree_x = task.output_degree_x;
                
                unsigned int current_degree_x = output_degree_x > Order ? output_degree_x - Order : 0;
                
                for(unsigned int step_id = 0; step_id < step_count; ++step_id) {
                
                    unsigned int in_polynomial_offset1 = ( + current_degree_x
                                                         ) * VLI__SIZE + input_elem_offset;
                    
                    unsigned int in_polynomial_offset2 = ( + (output_degree_x - current_degree_x)
                                                         ) * VLI__SIZE + input_elem_offset;
                
                    #pragma unroll
                    for(unsigned int i = 0; i < VLI__SIZE; ++i){
                        c1[i] = tex1Dfetch(tex_reference_1,in_polynomial_offset1+i);        
                    }
                    #pragma unroll
                    for(unsigned int i = 0; i < VLI__SIZE; ++i){
                        c2[i] = tex1Dfetch(tex_reference_2,in_polynomial_offset2+i);                 
                    } 
                
                    #pragma unroll
                    for(unsigned int i = 0; i < 2*VLI__SIZE; ++i)
                        res1[i] = 0;
                 
                    multiplies<NumBits>(res, res1, c1, c2); // the multiplication using boost pp
                 
                    current_degree_x++;
                }
                
                unsigned int coefficient_id =  output_degree_x;
                
                unsigned int * out2 = out + (coefficient_id * element_count *2* VLI__SIZE) + element_id; // coefficient->int_degree->element_id
                #pragma unroll
                for(unsigned int i = 0; i < 2*VLI__SIZE; ++i) {
                        // This is a strongly compute-bound kernel,
                        // so it is fine to waste memory bandwidth by using non-coalesced writes in order to have less instructions,
                        //     less synchronization points, less shared memory used (and thus greater occupancy) and greater scalability.
                        *out2 = res[i];
                        out2 += element_count;
                }
            } // end step count
        } // end for it

        };  // end function
    }; // end struct

    #undef VLI__ExtendStride
    #undef VLI__SIZE

    }//end namesoace detail
}//end namespace vli
