/*
*Very Large Integer Library, License - Version 1.0 - May 3rd, 2012
*
*Timothee Ewart - University of Geneva, 
*Andreas Hehn - Swiss Federal Institute of technology Zurich.
*
*Permission is hereby granted, free of charge, to any person or organization
*obtaining a copy of the software and accompanying documentation covered by
*this license (the "Software") to use, reproduce, display, distribute,
*execute, and transmit the Software, and to prepare derivative works of the
*Software, and to permit third-parties to whom the Software is furnished to
*do so, all subject to the following:
*
*The copyright notices in the Software and this entire statement, including
*the above license grant, this restriction and the following disclaimer,
*must be included in all copies of the Software, in whole or in part, and
*all derivative works of the Software, unless such copies or derivative
*works are solely in the form of machine-executable object code generated by
*a source language processor.
*
*THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
*IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
*FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
*SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
*FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
*ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
*DEALINGS IN THE SOFTWARE.
*/

#ifndef VLI_KARATSUBA_ASM_H
#define VLI_KARATSUBA_ASM_H

#include <boost/preprocessor/arithmetic/add.hpp>
#include <boost/preprocessor/arithmetic/mul.hpp>
#include <boost/preprocessor/arithmetic/sub.hpp>
#include <boost/preprocessor/repetition.hpp>
#include <boost/preprocessor/iteration/local.hpp>
#include <boost/preprocessor/comparison/equal.hpp>
#include <boost/preprocessor/stringize.hpp>

namespace vli {
   /* \cond I do not need this part in the doc*/
    namespace detail {

    template <std::size_t NumBits>
    inline void KA_add(boost::uint64_t* x, boost::uint64_t const* y);

    template <std::size_t NumBits>
    inline void KA_sub_extend(boost::uint64_t* x, boost::uint64_t const* y);

    template <std::size_t NumBits>
    inline void KA_add_extend(boost::uint64_t* x, boost::uint64_t const* y);

    template <std::size_t NumBits>
    inline void KA_sign_zero_extend(boost::uint64_t* x,  boost::uint64_t mask);

    template <std::size_t NumBits>
    inline boost::uint64_t KA_sub_b(boost::uint64_t* x, boost::uint64_t const* y); //return the mask

    template <std::size_t NumBits>
    inline boost::uint64_t KA_add_c(boost::uint64_t* x, boost::uint64_t const* y); //return the mask

    template <std::size_t NumBits>
    void KA_sign(boost::uint64_t* x, boost::uint64_t a);
    
    #define r(w, n, MAX)  BOOST_PP_COMMA_IF(n) BOOST_PP_STRINGIZE(+r)(*(x+n))
    #define g(w, n, MAX)  BOOST_PP_COMMA_IF(n) BOOST_PP_STRINGIZE(g)(*(y+n))
        
    #define addn128_n128_ka_cpu(w, n, MAX) \
        BOOST_PP_IF(n,"adcq %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,n))", %"BOOST_PP_STRINGIZE(n)"; \n\t","addq  %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,n))", %0; \n\t")

    #define addn128_n128_extend_ka_cpu(w, n, MAX) \
        BOOST_PP_IF(n,"adcq %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,BOOST_PP_ADD(n,1)))", %"BOOST_PP_STRINGIZE(n)"; \n\t","addq  %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,BOOST_PP_ADD(n,1)))", %0; \n\t")

    #define addn128_n128_zero_extend_ka_cpu(w, n, MAX) \
        BOOST_PP_IF(n,"adcq $0, %"BOOST_PP_STRINGIZE(n)"; \n\t","addq  %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,BOOST_PP_ADD(n,1)))", %0; \n\t") 


    #define subn128_n128_ka_r_cpu(w, n, MAX) \
        BOOST_PP_IF(n,"sbbq %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,BOOST_PP_ADD(n,1)))", %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(n,1))"; \n\t","subq  %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,BOOST_PP_ADD(n,1)))", %1; \n\t")
   
    #define addn64_bit_ka_cpu(w, n, MAX) \
        BOOST_PP_IF(n,"adcq $0, %"BOOST_PP_STRINGIZE(n)"; \n\t","addq  %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,n))", %0; \n\t")  /* n=0 no CB,  n!=0, second pass needs CB */  \

   
    #define FUNCTION_add_nbits_nbits(z, n, unused) \
    template<> \
    inline void KA_add<(n+1)*64>(boost::uint64_t* x,boost::uint64_t const* y){ \
        asm( \
            BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), addn128_n128_ka_cpu, BOOST_PP_ADD(n,1)) \
          : BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), r, ~) : BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), g, BOOST_PP_ADD(n,1)): "cc" \
        ); \
    }; \

    #define FUNCTION_add_extend_nbits_nbits(z, n, unused) \
    template<> \
    inline void KA_add_extend<(n+1)*64>(boost::uint64_t* x,boost::uint64_t const* y){ \
        asm( \
            BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), addn128_n128_extend_ka_cpu, BOOST_PP_ADD(n,1)) \
            "adcq $0 , %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(n,1))"; \n\t" \
            : BOOST_PP_REPEAT(BOOST_PP_ADD(n,2), r, ~): BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), g, BOOST_PP_ADD(n,1)): "cc" \
           ); \
    }; \

    #define FUNCTION_sign_zero_extend_nbits_nbits(z, n, unused) \
    template<> \
    inline void KA_sign_zero_extend<(n+1)*64>(boost::uint64_t* x,boost::uint64_t mask){ \
        for(int i(0); i < (n+2); ++i) \
            x[i] ^= mask; \
        mask >>= 63; \
        asm( \
            BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), addn128_n128_zero_extend_ka_cpu, BOOST_PP_ADD(n,1)) \
            "adcq $0 , %"BOOST_PP_STRINGIZE(BOOST_PP_ADD(n,1))"; \n\t" \
            : BOOST_PP_REPEAT(BOOST_PP_ADD(n,2), r, ~) : "g"(mask)  : "cc" \
           ); \
    }; \

    #define FUNCTION_add_nbits_bit(z, n, unused) \
    template<> \
    inline void KA_sign<(n+1)*64>(boost::uint64_t* x,boost::uint64_t mask){ \
        for(int i(0); i < (n+1); ++i) \
            x[i] ^= mask; \
        mask >>= 63; /* transform the mask to CB */ \
        asm (  \
           BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), addn64_bit_ka_cpu, BOOST_PP_ADD(n,1)) \
           :BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), r, ~) : "g"(mask) : "cc" \
        ); \
    }; \

    #define FUNCTION_sub_nbits_nbits_mask(z, n, unused) \
    template<> \
    inline boost::uint64_t KA_sub_b<(n+1)*64>(boost::uint64_t* x,boost::uint64_t const* y){ \
        boost::uint64_t sign(0); \
        asm( \
            BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), subn128_n128_ka_r_cpu, BOOST_PP_ADD(n,1)) \
            "setc %0; \n\t" /* get the CB*/\
           : "+m"(sign), BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), r, ~) : BOOST_PP_REPEAT(BOOST_PP_ADD(n,1), g, BOOST_PP_ADD(n,1)): "cc" \
        ); \
        return -sign; \
    }; \

    BOOST_PP_REPEAT(8, FUNCTION_add_nbits_nbits, ~)
    BOOST_PP_REPEAT(4, FUNCTION_add_extend_nbits_nbits, ~)
    BOOST_PP_REPEAT(4, FUNCTION_sign_zero_extend_nbits_nbits, ~)
    BOOST_PP_REPEAT(4, FUNCTION_add_nbits_bit,   ~)
    BOOST_PP_REPEAT(8, FUNCTION_sub_nbits_nbits_mask, ~)
        
//  A less recursive variant of Karatsuba-Ofman algorithm for Multiplying Operands of Size a Power of Two
//  Swedar S. Erdem Cetin Koc, coded section 4 Efficient Implementation of KOA
    template <std::size_t NumBits>
    struct K_helper{//lsb = partie haute, msb = partie basse
        static inline void  KA(boost::uint64_t* res0, boost::uint64_t const *  a, boost::uint64_t const *  b){
            boost::uint64_t am[NumBits/128];
            boost::uint64_t bm[NumBits/128];
            boost::uint64_t medium[NumBits/64+1];
            medium[NumBits/64] = 0;

            // step 3 and 4 not coded I direct use the data a and b 
            for(std::size_t i=0; i < NumBits/128; ++i){
                am[i] = a[i]; // step 2
                bm[i] = b[i+NumBits/128]; // step 5
            }
             
            boost::uint64_t mask_s1 = KA_sub_b<NumBits/2>(am,(a+NumBits/128)); // step 6, am = al - ah, ( ah = a + NumBits/128 arith ptr), mask is the sign 0 positif, -1 (0xffff .... ) negatif
            boost::uint64_t mask_s2 = KA_sub_b<NumBits/2>(bm,b); // step 7, bm = bh - bl ( bl = b), mask the sign again
            
            KA_sign<NumBits/2>(am,mask_s1); // step 6 next, it is just the absolute value
            KA_sign<NumBits/2>(bm,mask_s2); // step 7 next, absolute value again

            K_helper<NumBits/2>::KA(res0,a,b); // step 8
            K_helper<NumBits/2>::KA((res0+(2*NumBits)/128),(a+NumBits/128),(b+NumBits/128)); // step 9
            K_helper<NumBits/2>::KA(medium,am,bm); // step 10
            
            KA_sign_zero_extend<NumBits>(medium, (mask_s1^mask_s2)); // 0 +- medium, in both case I do 0 + Two Complementary method on medium, for the postive version it changes nothings, step 11a (+- medium)
            KA_add_extend<NumBits>(medium,res0); //  step 11a next
            KA_add_extend<NumBits>(medium,(res0+NumBits/64)); //  step 11a next
            KA_add<NumBits+64>((res0+(NumBits/64)/2),medium);  // 11b
        };
    };
        
    template <>
    struct K_helper<64>{
        static inline void KA(boost::uint64_t* res0, boost::uint64_t const *  a, boost::uint64_t const *  b){//
            /* =a means rax for lower part, =d means rdx for the higher part, = for writing, %0 directly vli_a[0] ready for mul vli[0] */
            asm("mulq %3;" :"=a"(res0[0]), "=d"(res0[1]) :"%0" (a[0]), "r"(b[0]): "cc");
        }
    };
        
    template <std::size_t NumBits>
    void karatsuba(vli<2*NumBits>& res, vli<NumBits> const& vli_a, vli<NumBits> const& vli_b){
        K_helper<NumBits>::KA(&res[0],&vli_a[0],&vli_b[0]);
    }
    
    #undef FUNCTION_add_nbits_nbits
    #undef FUNCTION_add_extend_nbits_nbits
    #undef FUNCTION_sign_zero_extend_nbits_nbits
    #undef FUNCTION_add_extend_nbits_nbits
    #undef FUNCTION_add_nbits_bit
    #undef FUNCTION_sub_nbits_nbits_mask
    #undef g // FIXME this name is unacceptable
    #undef r // FIXME this name is unacceptable
    } //detail
       /* \endcond I do not need this part in the doc*/
} //vli


#endif
