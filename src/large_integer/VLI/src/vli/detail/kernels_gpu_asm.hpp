/*
*Very Large Integer Library, License - Version 1.0 - May 3rd, 2012
*
*Timothee Ewart - University of Geneva, 
*Andreas Hehn - Swiss Federal Institute of technology Zurich.
*
*Permission is hereby granted, free of charge, to any person or organization
*obtaining a copy of the software and accompanying documentation covered by
*this license (the "Software") to use, reproduce, display, distribute,
*execute, and transmit the Software, and to prepare derivative works of the
*Software, and to permit third-parties to whom the Software is furnished to
*do so, all subject to the following:
*
*The copyright notices in the Software and this entire statement, including
*the above license grant, this restriction and the following disclaimer,
*must be included in all copies of the Software, in whole or in part, and
*all derivative works of the Software, unless such copies or derivative
*works are solely in the form of machine-executable object code generated by
*a source language processor.
*
*THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
*IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
*FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
*SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
*FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
*ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
*DEALINGS IN THE SOFTWARE.
*/

#include <boost/preprocessor/repetition.hpp>
#include <boost/preprocessor/arithmetic/add.hpp>
#include <boost/preprocessor/arithmetic/mul.hpp>
#include <boost/preprocessor/stringize.hpp>
#include <boost/preprocessor/punctuation/comma_if.hpp>

// number of iteration for pp add and mul
#define MAX_ITERATION_ADD 2
#define MAX_ITERATION_MUL 6
// macro for calculating the indices of the addition
#define I(i,N) BOOST_PP_ADD(i,BOOST_PP_MUL(6,N)) 

#define MUL_BLOCK_SIZE (((MULT_RESULT_DEGREE_BOUND_X*MULT_RESULT_DEGREE_BOUND_Y)/2U >= 256U) ? 256U : (((MULT_RESULT_DEGREE_BOUND_X*MULT_RESULT_DEGREE_BOUND_Y)/2U+32U-1U)/32U*32U)) // 32U is the warp size here
#define MAX_ITERATION_COUNT ((MULT_RESULT_DEGREE_BOUND_X*MULT_RESULT_DEGREE_BOUND_Y+31U)/32U)
#define INT_DEGREE ((MAX_NUMBER_OF_BITS_THE_LARGE_INTEGER_OCCUPIES+32-1)/32)
#define INT_DEGREE_PADDED (((INT_DEGREE>>1)<<1)+1)
#define SLICE (DEGREE_BOUND_X)
#define SLICE_PADDED (((SLICE>>1)<<1)+1)
#define SUM_BLOCK_SIZE 256


namespace vli{
    namespace detail{
    /* note : ptx is not pure GPU assembly, it is an intermediate,
     * moreover the ptx extented assembly does not support 64 bits integer
     * therefore I have to work on 32 bits, twice more operations for the addition
     * 4 times more for the multuplication
     */    
    inline void add384_384_gpu(unsigned int* x /* shared */, unsigned int const* y /* global */){
    /* this version 60 more ptx lines, so boost pp  
     *  
     * asm( "add.cc.u32   %0 , %0 , %1 ; \n\t" : "+r"(x[0]):"r"(y[0])); 
     * #pragma unroll
     * for(int i=1; i < 11; ++i)
     *     asm( "addc.cc.u32  %0 , %0 , %1 ; \n\t" : "+r"(x[i]):"r"(y[i])); 
     *
     * I have to break up into 2 parts because I can not have more than 30 input/output          
     * load/write operation are done by the compiler (!= ASM x80-86) 
     */
           #define add384_384_384_gpu(w, n, unused) \
               asm( \
                    BOOST_PP_IF(n,"addc.cc.u32 %0, %0, %6; \n\t","add.cc.u32  %0, %0, %6 ; \n\t") /* n=0 no CB,  n!=0, second pass needs CB */ \
                   "addc.cc.u32 %1, %1, %7 ; \n\t" /* x[1] += y[1] + CB                                                                     */ \
                   "addc.cc.u32 %2, %2, %8 ; \n\t" /* x[2] += y[2] + CB                                                                     */ \
                   "addc.cc.u32 %3, %3, %9 ; \n\t" /* x[3] += y[3] + CB                                                                     */ \
                   "addc.cc.u32 %4, %4, %10; \n\t" /* x[4] += y[4] + CB                                                                     */ \
                   "addc.cc.u32 %5, %5, %11; \n\t" /* x[5] += y[5] + CB                                                                     */ \
                   :"+r"(x[I(0,n)]),"+r"(x[I(1,n)]),"+r"(x[I(2,n)]),                                                                           \
                    "+r"(x[I(3,n)]),"+r"(x[I(4,n)]),"+r"(x[I(5,n)])                                                                            \
                   :"r"(y[I(0,n)]),"r"(y[I(1,n)]),"r"(y[I(2,n)]),                                                                              \
                    "r"(y[I(3,n)]),"r"(y[I(4,n)]),"r"(y[I(5,n)])                                                                               \
                  );
           BOOST_PP_REPEAT(MAX_ITERATION_ADD, add384_384_384_gpu, ~)

           #undef add384_384_384_gpu
    } //end add384_384_gpu 

    inline void mul384_384_gpu(unsigned int* x/* res local*/, unsigned int const* y /* shared */, unsigned int const* z /* shared */){
	    /*                   y[5] y[4] y[3] y[2] y[1] y[0]  %13 %12 %11 %10 %9 %8 
	     *                 X                          z[i], %7  i = 0 in my example
	     * _________________________________________________
	     * x[i+6] x[i+5] x[i+4] x[i+3] x[i+2] x[i+1] x[i+0], %6 %5 %4 %3 %2 %1 %0
	     * I multiply first low part and then high part, I avoid all carry bit propagation pbs
	     * The pp_if CB only possible when n!=0 because z is init to 0 by default
	     */
           #define mul384_192_192_gpu(w, n, unused) \
               asm( \
                  "mad.lo.cc.u32  %0, %8,  %7, %0; \n\t" /* c[i]   = a[0] * b[i] (low)  + c[i] (c[i]=0 for i=0) may generate carry bit (CB) */ \
                  "madc.lo.cc.u32 %1, %9,  %7, %1; \n\t" /* c[i+1] = a[1] * b[i] (low)  + c[i+1] + CB                                       */ \
                  "madc.lo.cc.u32 %2, %10, %7, %2; \n\t" /* c[i+2] = a[2] * b[i] (low)  + c[i+1] + CB                                       */ \
                  "madc.lo.cc.u32 %3, %11, %7, %3; \n\t" /* c[i+3] = a[3] * b[i] (low)  + c[i+3] + CB                                       */ \
                  "madc.lo.cc.u32 %4, %12, %7, %4; \n\t" /* c[i+4] = a[4] * b[i] (low)  + c[i+4] + CB                                       */ \
                  "madc.lo.cc.u32 %5, %13, %7, %5; \n\t" /* c[i+5] = a[5] * b[i] (low)  + c[i+5] + CB                                       */ \
                  BOOST_PP_IF(n,"addc.cc.u32 %6, 0, 0; \n\t",/* no extention n=0 */) /* c[i+6] += CB, n = 0 CB impossible                   */ \
                  "mad.hi.cc.u32  %1, %8,  %7, %1; \n\t" /* c[i+1] = a[0] * b[i] (high) + c[i+1] + CB (c[i]=0 for i=0)                      */ \
                  "madc.hi.cc.u32 %2, %9,  %7, %2; \n\t" /* c[i+2] = a[1] * b[i] (high) + c[i+2] + CB                                       */ \
                  "madc.hi.cc.u32 %3, %10, %7, %3; \n\t" /* c[i+3] = a[2] * b[i] (high) + c[i+3] + CB                                       */ \
                  "madc.hi.cc.u32 %4, %11, %7, %4; \n\t" /* c[i+4] = a[3] * b[i] (high) + c[i+4] + CB                                       */ \
                  "madc.hi.cc.u32 %5, %12, %7, %5; \n\t" /* c[i+5] = a[4] * b[i] (high) + c[i+5] + CB                                       */ \
                  "madc.hi.cc.u32 %6, %13, %7, %6; \n\t" /* c[i+6] = a[5] * b[i] (high) + c[i+6]                                            */ \
                  :"+r"(x[BOOST_PP_ADD(0,n)]),"+r"(x[BOOST_PP_ADD(1,n)]),"+r"(x[BOOST_PP_ADD(2,n)]),                                           \
                   "+r"(x[BOOST_PP_ADD(3,n)]),"+r"(x[BOOST_PP_ADD(4,n)]),"+r"(x[BOOST_PP_ADD(5,n)]),"+r"(x[BOOST_PP_ADD(6,n)])                 \
                  :"r"(z[n]),"r"(y[0]),"r"(y[1]),"r"(y[2]),"r"(y[3]),"r"(y[4]),"r"(y[5])                                                       \
                 );                                                                                                                            \

           BOOST_PP_REPEAT(MAX_ITERATION_MUL, mul384_192_192_gpu, ~)
           #undef mul384_192_192_gpu
	   } // end mul384_384_gpu

   #define ADC0_GPU(z, n, unused ) "addc.cc.u32 "BOOST_PP_STRINGIZE(BOOST_PP_CAT(pc,n))", 0, "BOOST_PP_STRINGIZE(BOOST_PP_CAT(pc,n))"; \n\t " 
   #define R_GPU(z, n, MAX) BOOST_PP_COMMA_IF(n)"+r"(x[BOOST_PP_ADD(n,MAX)])  

   #define pc0 %0
   #define pc1 %1
   #define pc2 %2
   #define pc3 %3
   #define pc4 %4
   #define pc5 %5
  
  // #define R_GPU(z,n, MAX) "x["BOOST_PP_STRINGIZE(BOOST_PP_ADD(MAX,n
//


    inline void muladd384_384_gpu(unsigned int* x/* res local*/, unsigned int const* y /* shared */, unsigned int const* z /* shared */){
    /*                   y[5] y[4] y[3] y[2] y[1] y[0]  %13 %12 %11 %10 %9 %8  
     *                 X                          z[i], %7  i = 0 in my example
     * _________________________________________________
     * x[i+6] x[i+5] x[i+4] x[i+3] x[i+2] x[i+1] x[i+0], %6 %5 %4 %3 %2 %1 %0
     * I multiply first low part and then high part, I avoid all carry bit propagation pbs
     * The pp_if CB only possible when n!=0 because z is init to 0 by default
     * as the res local is used several time, I have to propagate carry bit after every series of multiplication
     */
           #define mul384_192_192_gpu(w, n, unused) \
               asm( \
                  "mad.lo.cc.u32  %0, %7,  %6, %0; \n\t" /* c[i]   = a[0] * b[i] (low)  + c[i] (c[i]=0 for i=0) may generate carry bit (CB) */ \
                  "madc.lo.cc.u32 %1, %8,  %6, %1; \n\t" /* c[i+1] = a[1] * b[i] (low)  + c[i+1] + CB                                       */ \
                  "madc.lo.cc.u32 %2, %9,  %6, %2; \n\t" /* c[i+2] = a[2] * b[i] (low)  + c[i+1] + CB                                       */ \
                  "madc.lo.cc.u32 %3, %10, %6, %3; \n\t" /* c[i+3] = a[3] * b[i] (low)  + c[i+3] + CB                                       */ \
                  "madc.lo.cc.u32 %4, %11, %6, %4; \n\t" /* c[i+4] = a[4] * b[i] (low)  + c[i+4] + CB                                       */ \
                  "madc.lo.cc.u32 %5, %12, %6, %5; \n\t" /* c[i+5] = a[5] * b[i] (low)  + c[i+5] + CB                                       */ \
                  :"+r"(x[BOOST_PP_ADD(0,n)]),"+r"(x[BOOST_PP_ADD(1,n)]),"+r"(x[BOOST_PP_ADD(2,n)]),                                           \
                   "+r"(x[BOOST_PP_ADD(3,n)]),"+r"(x[BOOST_PP_ADD(4,n)]),"+r"(x[BOOST_PP_ADD(5,n)])                                            \
                  :"r"(z[n]),"r"(y[0]),"r"(y[1]),"r"(y[2]),"r"(y[3]),"r"(y[4]),"r"(y[5])                                                       \
                 );                                                                                                                            \
               asm( /*propation of the CB */                                                                                                   \
                  BOOST_PP_REPEAT(BOOST_PP_SUB(6,n), ADC0_GPU,~)                                                                               \
                  :BOOST_PP_REPEAT(BOOST_PP_SUB(6,n), R_GPU,BOOST_PP_ADD(6,n))                                                                 \
                  :                                                                                                                            \
                 );                                                                                                                            \
               asm(                                                                                                                            \
                  "mad.hi.cc.u32  %0, %7,  %6, %0; \n\t" /* c[i]   = a[0] * b[i]  (hi)  + c[i] (c[i]=0 for i=0) may generate carry bit (CB) */ \
                  "madc.hi.cc.u32 %1, %8,  %6, %1; \n\t" /* c[i+1] = a[1] * b[i]  (hi)  + c[i+1] + CB                                       */ \
                  "madc.hi.cc.u32 %2, %9,  %6, %2; \n\t" /* c[i+2] = a[2] * b[i]  (hi)  + c[i+1] + CB                                       */ \
                  "madc.hi.cc.u32 %3, %10, %6, %3; \n\t" /* c[i+3] = a[3] * b[i]  (hi)  + c[i+3] + CB                                       */ \
                  "madc.hi.cc.u32 %4, %11, %6, %4; \n\t" /* c[i+4] = a[4] * b[i]  (hi)  + c[i+4] + CB                                       */ \
                  "madc.hi.cc.u32 %5, %12, %6, %5; \n\t" /* c[i+5] = a[5] * b[i]  (hi)  + c[i+5] + CB                                       */ \
                  :"+r"(x[BOOST_PP_ADD(1,n)]),"+r"(x[BOOST_PP_ADD(2,n)]),"+r"(x[BOOST_PP_ADD(3,n)]),                                           \
                   "+r"(x[BOOST_PP_ADD(4,n)]),"+r"(x[BOOST_PP_ADD(5,n)]),"+r"(x[BOOST_PP_ADD(6,n)])                                            \
                  :"r"(z[n]),"r"(y[0]),"r"(y[1]),"r"(y[2]),"r"(y[3]),"r"(y[4]),"r"(y[5])                                                       \
                 );                                                                                                                            \
               BOOST_PP_IF(BOOST_PP_SUB(5,n),  /* last iteration no CB propagation so no if */                                                 \
               asm( /*propagation of the CB */                                                                                                 \
                  BOOST_PP_REPEAT(BOOST_PP_SUB(5,n), ADC0_GPU,~)                                                                               \
                  :BOOST_PP_REPEAT(BOOST_PP_SUB(5,n), R_GPU,BOOST_PP_ADD(7,n))                                                                 \
                  :                                                                                                                            \
                 ); , \
                   )                                                                                                                            

            BOOST_PP_REPEAT(MAX_ITERATION_MUL, mul384_192_192_gpu, ~)
           #undef mul384_192_192_lo_gpu
   } // end mul384_384_gpu

   inline void negate192_gpu(unsigned int* x){
       unsigned int one(1);
       unsigned int zero(0);
       asm( 
           "not.b32 %0, %0; \n\t"
           "not.b32 %1, %1; \n\t"
           "not.b32 %2, %2; \n\t"
           "not.b32 %3, %3; \n\t"
           "not.b32 %4, %4; \n\t"
           "not.b32 %5, %5; \n\t"
           "add.cc.u32  %0, %0, %6; \n\t"
           "addc.cc.u32 %1, %1, %7; \n\t"
           "addc.cc.u32 %2, %2, %7; \n\t"
           "addc.cc.u32 %3, %3, %7; \n\t"
           "addc.cc.u32 %4, %4, %7; \n\t"
           "addc.cc.u32 %5, %5, %7; \n\t"
           :"+r"(x[0]),"+r"(x[1]),"+r"(x[2]),"+r"(x[3]),"+r"(x[4]),"+r"(x[5])
           :"r"(one),"r"(zero)
       ); 
   }

   inline void negate384_gpu(unsigned int* x){
       unsigned int one(1);
       unsigned int zero(0);
       asm( 
           "not.b32 %0, %0; \n\t"
           "not.b32 %1, %1; \n\t"
           "not.b32 %2, %2; \n\t"
           "not.b32 %3, %3; \n\t"
           "not.b32 %4, %4; \n\t"
           "not.b32 %5, %5; \n\t"
           "not.b32 %6, %6; \n\t"
           "not.b32 %7, %7; \n\t"
           "not.b32 %8, %8; \n\t"
           "not.b32 %9, %9; \n\t"
           "not.b32 %10, %10; \n\t"
           "not.b32 %11, %11; \n\t"
           "add.cc.u32  %0, %0,   %12; \n\t"
           "addc.cc.u32 %1, %1,   %13; \n\t"
           "addc.cc.u32 %2, %2,   %13; \n\t"
           "addc.cc.u32 %3, %3,   %13; \n\t"
           "addc.cc.u32 %4, %4,   %13; \n\t"
           "addc.cc.u32 %5, %5,   %13; \n\t"
           "addc.cc.u32 %6, %6,   %13; \n\t"
           "addc.cc.u32 %7, %7,   %13; \n\t"
           "addc.cc.u32 %8, %8,   %13; \n\t"
           "addc.cc.u32 %9, %9,   %13; \n\t"
           "addc.cc.u32 %10, %10, %13; \n\t"
           "addc.cc.u32 %11, %11, %13; \n\t"
           :"+r"(x[0]),"+r"(x[1]),"+r"(x[2]),"+r"(x[3]),"+r"(x[4]),"+r"(x[5]),"+r"(x[6]),"+r"(x[7]),"+r"(x[8]),"+r"(x[9]),"+r"(x[10]),"+r"(x[11])
           :"r"(one),"r"(zero)
       ); 
   }

   } //end namespace detail
} //end namespace vli
